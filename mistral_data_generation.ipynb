{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738e8f9d-4cb9-4940-9cbb-c08fa9b4875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from mistralai import Mistral\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020f718-43cf-41db-b552-f29d379d12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\" #INSERT YOUR KEY HERE\n",
    "model = \"mistral-large-2407\"\n",
    "temperatures = [0.0, 0.7, 1.4]\n",
    "dataset_name = \"mistral_dataset_raw.csv\"\n",
    "b_df = pd.read_csv(\"prompts.csv\")\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "def talk_to_mistral(temp, prompt):\n",
    "    \n",
    "    chat_response = client.chat.complete(\n",
    "        model = model,\n",
    "        temperature = temp,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return chat_response.dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe293d6-804f-4f41-bf87-c1bfeee50af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the dataset\n",
    "first_prompt = \"Greet me in 5 tokens\"\n",
    "temp_0 = 0.7\n",
    "\n",
    "response_dict = talk_to_mistral(temp_0, first_prompt)\n",
    "response_dict[\"datetime\"] = datetime.now()\n",
    "response_dict[\"hash\"] = \"0000\"\n",
    "response_dict[\"temperature\"] = temp_0\n",
    "response_dict[\"prompt\"] = first_prompt\n",
    "response_dict[\"request_prompt_ID\"] = -1\n",
    "response_dict[\"response_text\"] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "response_dict[\"origin\"] = \"Greet\"\n",
    "response_dict[\"prompt_type\"] = \"open_ended\"\n",
    "\n",
    "pd.json_normalize(response_dict).to_csv(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdac6d7-5fe5-4070-b06d-d60b5ed9478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "no_works = []\n",
    "for i in range(len(b_df))[492:]:\n",
    "    for temp in temperatures:\n",
    "\n",
    "        try:\n",
    "            current_df = pd.read_csv(dataset_name)\n",
    "            \n",
    "            prompt = b_df.iloc[i,2]\n",
    "    \n",
    "            response_dict = talk_to_mistral(temp, prompt)\n",
    "            response_dict[\"datetime\"] = datetime.now()\n",
    "            response_dict[\"hash\"] = b_df.iloc[i,1]\n",
    "            response_dict[\"temperature\"] = temp\n",
    "            response_dict[\"prompt\"] = prompt\n",
    "            response_dict[\"request_prompt_ID\"] = b_df.index[i]\n",
    "            response_dict[\"response_text\"] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            response_dict[\"origin\"] = b_df.iloc[i,3]\n",
    "            response_dict[\"prompt_type\"] = b_df.iloc[i,4]\n",
    "    \n",
    "            # Create a row with the data\n",
    "            row_df = pd.json_normalize(response_dict)\n",
    "    \n",
    "    \n",
    "            # Merge the existing datasets\n",
    "            merged_df = pd.concat([current_df, row_df], axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "            # Save the merged_df in the directory CSV\n",
    "            merged_df.to_csv(dataset_name, index=False)\n",
    "    \n",
    "            # Print Done\n",
    "            print(i, temp)\n",
    "            print(response_dict[\"response_text\"])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "        except:\n",
    "            no_works.append((i, temp))\n",
    "            print(\"-----------------------------\")\n",
    "            print(f\"The following temp and request ID did not work: {i}, temp: {temp}\")\n",
    "            print(\"-----------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e8e1f-5a89-4f6f-ad69-154122b5659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the texts that could not be generated in the first round\n",
    "\n",
    "no_works2 = []\n",
    "\n",
    "for pair in no_works:\n",
    "\n",
    "    i, temp = pair\n",
    "    \n",
    "    try:\n",
    "        current_df = pd.read_csv(dataset_name)\n",
    "        \n",
    "        prompt = b_df.iloc[i,2]\n",
    "    \n",
    "        response_dict = talk_to_mistral(temp, prompt)\n",
    "        response_dict[\"datetime\"] = datetime.now()\n",
    "        response_dict[\"hash\"] = b_df.iloc[i,1]\n",
    "        response_dict[\"temperature\"] = temp\n",
    "        response_dict[\"prompt\"] = prompt\n",
    "        response_dict[\"request_prompt_ID\"] = b_df.index[i]\n",
    "        response_dict[\"response_text\"] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "        response_dict[\"origin\"] = b_df.iloc[i,3]\n",
    "        response_dict[\"prompt_type\"] = b_df.iloc[i,4]\n",
    "    \n",
    "        # Create a row with the data\n",
    "        row_df = pd.json_normalize(response_dict)\n",
    "    \n",
    "    \n",
    "        # Merge the existing datasets\n",
    "        merged_df = pd.concat([current_df, row_df], axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "        # Save the merged_df in the directory CSV\n",
    "        merged_df.to_csv(dataset_name, index=False)\n",
    "    \n",
    "        # Print Done\n",
    "        print(i, temp)\n",
    "        print(response_dict[\"response_text\"])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    except:\n",
    "        no_works2.append((i, temp))\n",
    "        print(\"-----------------------------\")\n",
    "        print(f\"The following temp and request ID did not work: {i}, temp: {temp}\")\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a6e8d-8955-4aa5-bc48-26496a8e902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"mistral_dataset_raw.csv\")\n",
    "print(len(raw_df))\n",
    "raw_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda4544-4886-4f46-9354-00ca5afc43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_duplicates_df = raw_df.drop_duplicates(subset=['temperature', 'request_prompt_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330e590-de39-4dcc-9b57-0047db03d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the sizi difference\n",
    "len(raw_df), len(non_duplicates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19f782-5d10-4111-afb9-fdc13225c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = non_duplicates_df[[\"request_prompt_ID\", \"hash\", \"temperature\", \"origin\", \"prompt_type\", \"prompt\", \"response_text\"]]\n",
    "\n",
    "clean_df = clean_df[clean_df[\"request_prompt_ID\"] >= 0].reset_index()\n",
    "\n",
    "clean_df = clean_df.sort_values(by=[\"request_prompt_ID\", \"temperature\"]).drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4dbbc-600e-4408-8046-a13a4856cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"mistral_ai_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f17af9-efff-4ebb-beae-951ae05cb64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['request_prompt_ID', 'hash', 'temperature', 'origin', 'prompt_type',\n",
       "       'prompt', 'response_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the generated dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"mistral_ai_dataset.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10a204d-4252-40d9-98b0-5f9917a840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0.1'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8437e7c1-7e84-4233-9a60-10e93566a350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given a passage, please paraphrase it. The content should be the same. The passage is:ни чего нового как правильноНичего страшного. View more. 1. И Новый год как раз и есть такой пункт. Чтобы вы могли правильно воспользоваться «остановкой», AdMe.ru расскажет, '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following prompt (hash: 401104c55e54c0c969e8b0fd0f0302f4) is in russian so I will delete it.\n",
    "df[df[\"hash\"] == \"401104c55e54c0c969e8b0fd0f0302f4\"].prompt[4731][:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83526d52-0a25-4366-8fd4-959118eccf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"hash\"] != \"401104c55e54c0c969e8b0fd0f0302f4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8fe39b-bcd6-4fd9-ad3a-8f242bdf777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mistral_ai_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
