{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006605-6c39-4404-b8ff-31986fe032b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import SCL\n",
    "importlib.reload(SCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bffb4b31-5f1c-4124-9635-3bf9e96c53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_0_val.pkl', 'rb') as file:\n",
    "    temp_0_val = pickle.load(file)\n",
    "with open('temp_0_val_targs.pkl', 'rb') as file:\n",
    "    temp_0_val_targs = pickle.load(file)\n",
    "    \n",
    "with open('temp_7_val.pkl', 'rb') as file:\n",
    "    temp_7_val = pickle.load(file)\n",
    "with open('temp_7_val_targs.pkl', 'rb') as file:\n",
    "    temp_7_val_targs = pickle.load(file)\n",
    "\n",
    "with open('temp_14_val.pkl', 'rb') as file:\n",
    "    temp_14_val = pickle.load(file)\n",
    "with open('temp_14_val_targs.pkl', 'rb') as file:\n",
    "    temp_14_val_targs = pickle.load(file)\n",
    "\n",
    "with open('temp_all_val.pkl', 'rb') as file:\n",
    "    temp_all_val = pickle.load(file)\n",
    "with open('temp_all_val_targs.pkl', 'rb') as file:\n",
    "    temp_all_val_targs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d0ec4-824f-42e0-88c1-7365be53e4cb",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f389c7a-6414-4468-a40e-08e903b8587c",
   "metadata": {},
   "source": [
    "One way to evaluate model performance is to bootstrap the unseen data in the test set and aggregate model accuracies across many samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0993524e-3c18-4af6-a92c-0f2a3fc312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset object to feed into the dataloader\n",
    "    \"\"\"\n",
    "    def __init__(self, embs, targs):\n",
    "        \"\"\"\n",
    "        Class initializer\n",
    "\n",
    "        embs: concatenated CLS embeddings and feature vectors\n",
    "        targs: base truth model numbers\n",
    "        \"\"\"\n",
    "        self.embs = embs\n",
    "        self.targs = targs \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Method used by data loader to output data\n",
    "        \n",
    "        idx: random batch index from dataloader\n",
    "\n",
    "        Returns: \n",
    "        Tuple with batch embeddings at [0] and batch base truth targets at [1]\n",
    "        \"\"\"\n",
    "        return self.embs[idx], self.targs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c7869aa-d36f-412f-8a19-a62c4618c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "dataset_0 = WordEmbeddingDataset(temp_0_val, temp_0_val_targs)\n",
    "dataset_7 = WordEmbeddingDataset(temp_7_val, temp_7_val_targs)\n",
    "dataset_14 = WordEmbeddingDataset(temp_14_val, temp_14_val_targs)\n",
    "dataset_all = WordEmbeddingDataset(temp_all_val, temp_all_val_targs)\n",
    "\n",
    "data_loader_0_val = DataLoader(dataset_0, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "data_loader_7_val = DataLoader(dataset_7, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "data_loader_14_val = DataLoader(dataset_14, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "data_loader_all_val = DataLoader(dataset_all, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166f86d6-200b-4294-a953-3998d8fd39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_class, hidden_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.02\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, feature):\n",
    "        return self.fc(torch.tanh(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb93d52-909e-4294-8c28-059fd89e3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAM(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, hidden_dropout_prob):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)\n",
    "        self.fc = nn.Linear(embed_size, hidden_size)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.2\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, text):\n",
    "        batch,  dim = text.size()\n",
    "        feat = self.fc(torch.tanh(self.dropout(text.view(batch, dim))))\n",
    "        feat = F.normalize(feat, dim=1)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f705a2ea-f7fe-4071-a5b2-9d7935a06034",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, embs, targs, model_filepath):\n",
    "        RANDOM_STATE = 42\n",
    "        HIDDEN_SIZE = 256\n",
    "        DROPOUT_PERCENT = 0.3\n",
    "        NUM_FEATURES = 797\n",
    "        NUM_CLASSES = 3\n",
    "        model_data = torch.load(model_filepath)\n",
    "        self.fam = FAM(NUM_FEATURES, HIDDEN_SIZE, DROPOUT_PERCENT)\n",
    "        self.classifier = Classifier(HIDDEN_SIZE, NUM_CLASSES, DROPOUT_PERCENT)\n",
    "        self.fam.load_state_dict(model_data['fam_state_dict'])\n",
    "        self.classifier.load_state_dict(model_data['classifier_state_dict'])\n",
    "        self.embs = embs\n",
    "        self.targs = targs\n",
    "        self.rng = np.random.default_rng(RANDOM_STATE)\n",
    "        \n",
    "        \n",
    "    def get_bootstrap_dataloader(self):\n",
    "        BATCH_SIZE = 100\n",
    "        np.random.seed(42)\n",
    "        num_samples = len(self.embs)\n",
    "        bootstrap_indices = self.rng.choice(np.arange(num_samples), size=num_samples, replace=True)\n",
    "        sample_embs = [self.embs[idx] for idx in bootstrap_indices]\n",
    "        sample_targs = [self.targs[idx] for idx in bootstrap_indices]\n",
    "        dataset = WordEmbeddingDataset(sample_embs, sample_targs)\n",
    "        data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "        return data_loader\n",
    "\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        # Set networks to eval mode\n",
    "        self.fam.eval()  \n",
    "        self.classifier.eval()\n",
    "    \n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        with torch.no_grad():  \n",
    "            for data in data_loader:\n",
    "                embs = data[0].squeeze(1)  \n",
    "                targets = data[1].tolist()\n",
    "                \n",
    "                fam_output = self.fam(embs)\n",
    "                final_output = self.classifier(fam_output)\n",
    "                preds = final_output.argmax(1).tolist()\n",
    "                \n",
    "                total += len(preds) \n",
    "                correct += np.sum(np.array(preds) == np.array(targets))  \n",
    "    \n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "\n",
    "    def run_bootstrap(self, num_iterations):\n",
    "        accuracies = []\n",
    "        for _ in tqdm(range(num_iterations)):\n",
    "            data_loader = self.get_bootstrap_dataloader()\n",
    "            accuracy = self.evaluate(data_loader)\n",
    "            accuracies.append(accuracy)\n",
    "        return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da1e09f-2748-4bf5-8cc2-b7fe24e34be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0_model = Model(temp_0_val, temp_0_val_targs, 'temp_0_models.pth')\n",
    "temp_0_accuracy = temp_0_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d316b8a-d418-4bee-9479-e76f2573a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_7_model = Model(temp_7_val, temp_7_val_targs, 'temp_7_models.pth')\n",
    "temp_7_accuracy = temp_7_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5132ed-7822-4842-af8b-ab9a0cf882f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_14_model = Model(temp_14_val, temp_14_val_targs, 'temp_14_models.pth')\n",
    "temp_14_accuracy = temp_14_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313225c4-48a4-46c9-9d41-327224c3a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_all_model = Model(temp_all_val, temp_all_val_targs, 'temp_all_models.pth')\n",
    "temp_all_accuracy = temp_all_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d537037-95e5-4dd3-8cdb-5f2c26228601",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'temp_0':temp_0_accuracy, 'temp_7':temp_7_accuracy, 'temp_14':temp_14_accuracy, 'temp_all':temp_all_accuracy}\n",
    "bootstrap_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd80aa-7d55-4c5b-b569-be525f6b09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc2226-2fc1-4cba-8887-058151e9b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histogram_0 = alt.Chart(bootstrap_df).mark_line(opacity=0.7, color='blue').encode(\n",
    "    alt.X('temp_0:Q', bin=True, title='Accuracy'),\n",
    "    alt.Y('count():Q', title='Frequency')  \n",
    ")\n",
    "\n",
    "histogram_7 = alt.Chart(bootstrap_df).mark_line(opacity=0.7, color='red').encode(\n",
    "    alt.X('temp_7:Q', bin=True, title='Accuracy'),\n",
    "    alt.Y('count():Q', title='Frequency')  \n",
    ")\n",
    "\n",
    "histogram_14 = alt.Chart(bootstrap_df).mark_line(opacity=0.7, color='green').encode(\n",
    "    alt.X('temp_14:Q', bin=True, title='Accuracy'),\n",
    "    alt.Y('count():Q', title='Frequency')  \n",
    ").properties(\n",
    "    title='Classifier Accuracy at Varying Temperatures'\n",
    ")\n",
    "\n",
    "histogram_all = alt.Chart(bootstrap_df).mark_line(opacity=0.7, color='orange').encode(\n",
    "    alt.X('temp_all:Q', bin=True, title='Accuracy'),\n",
    "    alt.Y('count():Q', title='Frequency')  \n",
    ").properties(\n",
    "    title='Classifier Accuracy at Varying Temperatures'\n",
    ")\n",
    "\n",
    "combined_histogram = alt.layer(\n",
    "    histogram_0,\n",
    "    histogram_7,\n",
    "    histogram_14,\n",
    "    histogram_all\n",
    ")\n",
    "\n",
    "\n",
    "combined_histogram.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9edd02ee-e91f-4188-803c-8ebc9b742148",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_removal_list = ['Average Word Length', 'Stopword Ratio', 'MTTR', \"ADJ\", \"ADP\", \n",
    "                        \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\", \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \n",
    "                \"PRON\", \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\", \"SPACE\", 'Average Words Per Sentence', 'Active Voice', \n",
    "                        'Present Tense', 'Sentences Per Paragraph', 'Words Per Paragraph', 'Punctuation Per Word', 'Capitals Per Word']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4afc4-506f-4dad-8803-8fce6c945066",
   "metadata": {},
   "source": [
    "## 1.1 Ablation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca24dd-71b3-4f52-bd66-2b0d732319b5",
   "metadata": {},
   "source": [
    "The CLS embeddings generated by BERT have 768 features. These features are not interpretable by humans because they have been abstracted and aggregated through BERT's networks. However, the combined embeddings our model uses includes 29 normalized structural, syntactical, and lexical features that are easily understood by humans. We will remove each type of feature by substituting 0 for those column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f0e159c-45bc-4160-841c-1785007a8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc_0 = np.mean(temp_0_accuracy)\n",
    "avg_acc_7 = np.mean(temp_7_accuracy)\n",
    "avg_acc_14 = np.mean(temp_14_accuracy)\n",
    "avg_acc_all = np.mean(temp_all_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "820c352b-7688-4429-8e81-c2456da1d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lexical ablation embeddings\n",
    "def get_lexical_ablations(data):\n",
    "    return [\n",
    "    torch.tensor(np.concatenate((embedding[0, 0:746], np.zeros(22), embedding[0, 768:])), dtype=torch.float32).unsqueeze(0) for embedding in data\n",
    "]\n",
    "temp_0_lex_embs = get_lexical_ablations(temp_0_val)\n",
    "temp_7_lex_embs = get_lexical_ablations(temp_7_val)\n",
    "temp_14_lex_embs = get_lexical_ablations(temp_14_val)\n",
    "temp_all_lex_embs = get_lexical_ablations(temp_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c24f1df-d795-425c-bcb5-7bc368bf5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create syntactic ablation embeddings\n",
    "def get_syntactic_ablations(data):\n",
    "    return [\n",
    "    torch.tensor(np.concatenate((embedding[0, 0:768], np.zeros(3), embedding[0, 771:])), dtype=torch.float32).unsqueeze(0) for embedding in data\n",
    "]\n",
    "temp_0_syn_embs = get_syntactic_ablations(temp_0_val)\n",
    "temp_7_syn_embs = get_syntactic_ablations(temp_7_val)\n",
    "temp_14_syn_embs = get_syntactic_ablations(temp_14_val)\n",
    "temp_all_syn_embs = get_syntactic_ablations(temp_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e17152c4-871c-4f0c-8c57-308aaa4410ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structural ablation embeddings\n",
    "def get_structural_ablations(data):\n",
    "    return [torch.tensor(np.concatenate((embedding[0, 0:793], np.zeros(4))), dtype=torch.float32).unsqueeze(0) for embedding in data]\n",
    "temp_0_struc_embs = get_structural_ablations(temp_0_val)\n",
    "temp_7_struc_embs = get_structural_ablations(temp_7_val)\n",
    "temp_14_struc_embs = get_structural_ablations(temp_14_val)\n",
    "temp_all_struc_embs = get_structural_ablations(temp_all_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8c388-680b-4d5f-95ef-594364c4979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0_lex_model = Model(temp_0_lex_embs, temp_0_val_targs, 'temp_0_models.pth')\n",
    "temp_0_lex_accuracy = temp_0_lex_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9244041-2819-4192-baa9-83ee74627751",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_7_lex_model = Model(temp_7_lex_embs, temp_7_val_targs, 'temp_7_models.pth')\n",
    "temp_7_lex_accuracy = temp_7_lex_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120e523-8595-4297-b505-f7f6a86577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_14_lex_model = Model(temp_14_lex_embs, temp_14_val_targs, 'temp_14_models.pth')\n",
    "temp_14_lex_accuracy = temp_14_lex_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba46601-7013-4056-a846-69b727f896d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_all_lex_model = Model(temp_all_lex_embs, temp_all_val_targs, 'temp_all_models.pth')\n",
    "temp_all_lex_accuracy = temp_all_lex_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850efdc6-4017-4671-982f-b9ebf69eb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temp 0: ')\n",
    "print(avg_acc_0, np.mean(temp_0_lex_accuracy))\n",
    "print('Temp 0.7: ')\n",
    "print(avg_acc_7, np.mean(temp_7_lex_accuracy))\n",
    "print('Temp 1.4: ')\n",
    "print(avg_acc_14, np.mean(temp_14_lex_accuracy))\n",
    "print('Temp all: ')\n",
    "print(avg_acc_all, np.mean(temp_all_lex_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b2027-d8cb-4976-8799-2212c0b1314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0_struc_model = Model(temp_0_struc_embs, temp_0_val_targs, 'temp_0_models.pth')\n",
    "temp_0_struc_accuracy = temp_0_struc_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179006c-6d51-4cf2-bc6f-61d6ff108ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_7_struc_model = Model(temp_7_struc_embs, temp_7_val_targs, 'temp_7_models.pth')\n",
    "temp_7_struc_accuracy = temp_7_struc_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15534215-5292-469a-89f8-0a71923ea765",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_14_struc_model = Model(temp_14_struc_embs, temp_14_val_targs, 'temp_14_models.pth')\n",
    "temp_14_struc_accuracy = temp_14_struc_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42923d03-b4cc-4178-ba83-b71ecd3ab0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_all_struc_model = Model(temp_all_struc_embs, temp_all_val_targs, 'temp_all_models.pth')\n",
    "temp_all_struc_accuracy = temp_all_struc_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1950a8-9f09-4a39-82a3-a7c680993994",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temp 0: ')\n",
    "print(avg_acc_0, np.mean(temp_0_struc_accuracy))\n",
    "print('Temp 0.7: ')\n",
    "print(avg_acc_7, np.mean(temp_7_struc_accuracy))\n",
    "print('Temp 1.4: ')\n",
    "print(avg_acc_14, np.mean(temp_14_struc_accuracy))\n",
    "print('Temp all: ')\n",
    "print(avg_acc_all, np.mean(temp_all_struc_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cda118-e680-4952-912f-618ba4711ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_0_syn_model = Model(temp_0_syn_embs, temp_0_val_targs, 'temp_0_models.pth')\n",
    "temp_0_syn_accuracy = temp_0_syn_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff00cb-1547-42af-8f24-1e35e219be19",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_7_syn_model = Model(temp_7_syn_embs, temp_7_val_targs, 'temp_7_models.pth')\n",
    "temp_7_syn_accuracy = temp_7_syn_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa752d-8a23-46dd-9ded-03a010cd8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_14_syn_model = Model(temp_14_syn_embs, temp_14_val_targs, 'temp_14_models.pth')\n",
    "temp_14_syn_accuracy = temp_14_syn_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d071b62-07a2-48d8-9106-936c4d31c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_all_syn_model = Model(temp_all_syn_embs, temp_all_val_targs, 'temp_all_models.pth')\n",
    "temp_all_syn_accuracy = temp_all_syn_model.run_bootstrap(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab292e76-2523-44ca-b2fe-f5c1d3b57714",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temp 0: ')\n",
    "print(avg_acc_0, np.mean(temp_0_syn_accuracy))\n",
    "print('Temp 0.7: ')\n",
    "print(avg_acc_7, np.mean(temp_7_syn_accuracy))\n",
    "print('Temp 1.4: ')\n",
    "print(avg_acc_14, np.mean(temp_14_syn_accuracy))\n",
    "print('Temp all: ')\n",
    "print(avg_acc_all, np.mean(temp_all_syn_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f63a4-15d3-4546-8c2a-bf7aba10d965",
   "metadata": {},
   "source": [
    "It appears removing the stylometric feature vectors did little to change model accuracy. For processing improvements, future iterations of this model may omit the stylometric feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df38d22-aa93-4620-9409-6d086f6a1ddd",
   "metadata": {},
   "source": [
    "## 1.2 Hyperparameter Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739cf54-fbd9-41ae-bdc6-2f28ec76a6a1",
   "metadata": {},
   "source": [
    "The hyperparameters available to be tuned in our model are hidden_size_1, hidden_size_2, dropout_percent, learning_rate, step_size, supconloss_temperature, and gamma. As the project is based around contrastive loss, we would like to investigate the sensitivity of hidden_size_2 (number of features being fed into the contrastive loss function) and supconloss_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963fedc-fa8d-41c9-9754-f3ef6ff7f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hidden_size_2 sensitivity\n",
    "hidden_sizes = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "temp_0_test_accuracies = []\n",
    "temp_7_test_accuracies = []\n",
    "temp_14_test_accuracies = []\n",
    "temp_all_test_accuracies = []\n",
    "\n",
    "for hidden_size in hidden_sizes:\n",
    "    temp_0_model = SCL.ModelGenerator(SCL.data_loader_0_train, SCL.data_loader_0_test)\n",
    "    temp_0_model.gen_model(hidden_size, 0.07)\n",
    "    temp_0_test_accuracies.append(temp_0_model.test_accuracy(data_loader_0_val))\n",
    "    temp_7_model = SCL.ModelGenerator(SCL.data_loader_7_train, SCL.data_loader_7_test)\n",
    "    temp_7_model.gen_model(hidden_size, 0.07)\n",
    "    temp_7_test_accuracies.append(temp_7_model.test_accuracy(data_loader_7_val))\n",
    "    temp_14_model = SCL.ModelGenerator(SCL.data_loader_14_train, SCL.data_loader_14_test)\n",
    "    temp_14_model.gen_model(hidden_size, 0.07)\n",
    "    temp_14_test_accuracies.append(temp_14_model.test_accuracy(data_loader_14_val))\n",
    "    temp_all_model = SCL.ModelGenerator(SCL.data_loader_all_train, SCL.data_loader_all_test)\n",
    "    temp_all_model.gen_model(hidden_size, 0.07)\n",
    "    temp_all_test_accuracies.append(temp_all_model.test_accuracy(data_loader_all_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7b39851e-e158-491f-a9dc-4240007f9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'temp_0':temp_0_test_accuracies, 'temp_7':temp_7_test_accuracies, 'temp_14':temp_14_test_accuracies, \n",
    "        'temp_all':temp_all_test_accuracies}\n",
    "hidden_size_df = pd.DataFrame(data)\n",
    "hidden_size_df.index = hidden_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85130c4a-cf0c-46de-ae3e-d603289018a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hidden_size_df.index, hidden_size_df['temp_0'], label='Temperature 0', color='red', marker='o')\n",
    "plt.plot(hidden_size_df.index, hidden_size_df['temp_7'], label='Temperature 7', color='blue', marker='o')\n",
    "plt.plot(hidden_size_df.index, hidden_size_df['temp_14'], label='Temperature 14', color='green', marker='o')\n",
    "plt.plot(hidden_size_df.index, hidden_size_df['temp_all'], label='Temperature All', color='yellow', marker='o')\n",
    "\n",
    "\n",
    "plt.title('Test Set Accuracy by Projection Head Hidden Layer Size')\n",
    "plt.xlabel('Hidden Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(hidden_size_df.index) \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6553c3-001f-42b1-8e9b-77a161a1b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze supcontemp sensitivity\n",
    "temps = [0.01, 0.05, 0.10, 0.15, 0.2, 0.25, 0.30]\n",
    "temp_0_supcon_accuracies = []\n",
    "temp_7_supcon_accuracies = []\n",
    "temp_14_supcon_accuracies = []\n",
    "temp_all_supcon_accuracies = []\n",
    "\n",
    "for temp in temps:\n",
    "    temp_0_model = SCL.ModelGenerator(SCL.data_loader_0_train, SCL.data_loader_0_test)\n",
    "    temp_0_model.gen_model(128, temp)\n",
    "    temp_0_supcon_accuracies.append(temp_0_model.test_accuracy(data_loader_0_val))\n",
    "    temp_7_model = SCL.ModelGenerator(SCL.data_loader_7_train, SCL.data_loader_7_test)\n",
    "    temp_7_model.gen_model(128, temp)\n",
    "    temp_7_supcon_accuracies.append(temp_7_model.test_accuracy(data_loader_7_val))\n",
    "    temp_14_model = SCL.ModelGenerator(SCL.data_loader_14_train, SCL.data_loader_14_test)\n",
    "    temp_14_model.gen_model(128, temp)\n",
    "    temp_14_supcon_accuracies.append(temp_14_model.test_accuracy(data_loader_14_val))\n",
    "    temp_all_model = SCL.ModelGenerator(SCL.data_loader_all_train, SCL.data_loader_all_test)\n",
    "    temp_all_model.gen_model(128, temp)\n",
    "    temp_all_supcon_accuracies.append(temp_all_model.test_accuracy(data_loader_all_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97a69169-fb8c-4f15-9ea1-da7992087521",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'temp_0':temp_0_supcon_accuracies, 'temp_7':temp_7_supcon_accuracies, 'temp_14':temp_14_supcon_accuracies, \n",
    "        'temp_all':temp_all_supcon_accuracies}\n",
    "supcon_temp_df = pd.DataFrame(data)\n",
    "supcon_temp_df.index = temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b26dfd1-008b-4fda-b2d8-212c6bd839ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "supcon_temp_df.drop(supcon_temp_df.tail(1).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e4707-b528-49e7-a891-b4e80265d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(supcon_temp_df.index, supcon_temp_df['temp_0'], label='Temperature 0', color='red', marker='o')\n",
    "plt.plot(supcon_temp_df.index, supcon_temp_df['temp_7'], label='Temperature 7', color='blue', marker='o')\n",
    "plt.plot(supcon_temp_df.index, supcon_temp_df['temp_14'], label='Temperature 14', color='green', marker='o')\n",
    "plt.plot(supcon_temp_df.index, supcon_temp_df['temp_all'], label='Temperature All', color='yellow', marker='o')\n",
    "\n",
    "\n",
    "plt.title('Test Set Accuracy by Contrastive Loss Function Temperature')\n",
    "plt.xlabel('Hidden Size')\n",
    "plt.ylabel('Loss Temperature')\n",
    "plt.xticks(supcon_temp_df.index) \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e80166-8bdc-4355-8659-224cf21951b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
