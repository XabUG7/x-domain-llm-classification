{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation involves running the following cells repeatedly, changing the values for domain and model_temp to hit every combination of those variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "from ChatGPT_Data_Generation import OpenAIMisinfoBatchManager, process_batch_output_file\n",
    "from creds import OPENAI_KEY\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BatchDataContainer:\n",
    "    \"\"\"\n",
    "    A dataclass to hold information about a batch of prompts to be sent to the OpenAI API.\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame\n",
    "    output_filepath: str = None\n",
    "    error_filepath: str = None\n",
    "    batch_id: str = None\n",
    "    misinfo_engine: OpenAIMisinfoBatchManager = None\n",
    "\n",
    "\n",
    "def setup_logger():\n",
    "    \"\"\"\n",
    "    Set up the logger for the script.\n",
    "    \"\"\"\n",
    "    # Create a logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Create a file handler that logs to a new file each time the script is run\n",
    "    log_filename = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S.log\")\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Create a stream handler that logs to the terminal\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Create a formatter and set it for both handlers\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    stream_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add the handlers to the logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    logger.info(\"Logger setup complete.\")\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "prompts_csv_path = \"data/prompts.csv\"\n",
    "domain = \"paraphrase\" # \"rewrite\" or \"paraphrase\" or \"open_ended\"\n",
    "model_temp = 1.4\n",
    "batch_size = 50\n",
    "output_filepath_template = \"{}_misinfo_responses_{}.jsonl\"\n",
    "error_filepath_template = \"{}_misinfo_errors_{}.jsonl\"\n",
    "results_filename_template = \"model_{}___temp_{}___domain_{}___{}.csv\"\n",
    "raw_csv_df = pd.read_csv(\"data/prompts.csv\")\n",
    "full_prompts_df = raw_csv_df[raw_csv_df[\"type\"] == domain]\n",
    "\n",
    "if domain not in [\"rewrite\", \"paraphrase\", \"open_ended\"]:\n",
    "    raise ValueError(\"Domain must be one of 'rewrite', 'paraphrase', or 'open_ended'.\")\n",
    "\n",
    "# Break up the prompts into batches of batch_size\n",
    "batch_list = []\n",
    "for i in range(0, len(full_prompts_df), batch_size):\n",
    "    batch_df = full_prompts_df[i:i+batch_size]\n",
    "    batch_list.append(BatchDataContainer(df=batch_df))\n",
    "\n",
    "for i, batch_data in enumerate(batch_list):\n",
    "    batch_df = batch_data.df\n",
    "    misinfo_engine = OpenAIMisinfoBatchManager(temp=model_temp,\n",
    "                                                top_p=.9,\n",
    "                                                api_key=OPENAI_KEY)\n",
    "    misinfo_engine.send_batch_misinfo_request(batch_df)\n",
    "    output_filepath = output_filepath_template.format(domain, misinfo_engine.batch_id)\n",
    "    error_filepath = error_filepath_template.format(domain, misinfo_engine.batch_id)\n",
    "    \n",
    "    # Update the dataclass instance with the new information\n",
    "    batch_data.output_filepath = output_filepath\n",
    "    batch_data.error_filepath = error_filepath\n",
    "    batch_data.batch_id = misinfo_engine.batch_id\n",
    "    batch_data.misinfo_engine = misinfo_engine\n",
    "    \n",
    "    print(\"Misinformation generation request sent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch_data in enumerate(batch_list):\n",
    "    misinfo_engine = batch_data.misinfo_engine\n",
    "\n",
    "    # Use the dataclass fields for output_filepath and error_filepath\n",
    "    misinfo_engine.retrieve_batch_results(output_filepath=batch_data.output_filepath,\n",
    "                                        error_filepath=batch_data.error_filepath,\n",
    "                                        max_wait_time=24 * 60 * 60,  # Wait for up to 24 hours\n",
    "                                        status_check_interval=.5 * 60)  # Check status every 30 seconds\n",
    "    \n",
    "    print(\"Misinformation generation request completed.\")\n",
    "    \n",
    "    # Process the output file using the path stored in the dataclass\n",
    "    output_df = process_batch_output_file(file_path=batch_data.output_filepath)\n",
    "    \n",
    "    # Save the output dataframe to a CSV file using the batch-specific information\n",
    "    output_df.to_csv(results_filename_template.format(misinfo_engine.model, \n",
    "                                                      misinfo_engine.temp, \n",
    "                                                      domain, \n",
    "                                                      misinfo_engine.batch_id), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell multiple times, changing the target_temp value to each of the model temp values, to consolidate the generated data into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "directory = 'data'\n",
    "data_master_path = 'data/data_master.csv'\n",
    "# The temperature value you're filtering by (e.g., 0, 0.7, 1.4)\n",
    "target_temp = 0  # Set the temp you want to filter by here\n",
    "\n",
    "# Load the prompts.csv file\n",
    "master_df = pd.read_csv(data_master_path)\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Split the filename to extract the model and temp\n",
    "        parts = filename.split('___')\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        \n",
    "        model_name = parts[0].split('_')[1]\n",
    "        temp_value = float(parts[1].split('_')[1])\n",
    "        domain = parts[2].split('_')[1]\n",
    "        \n",
    "        # Check if the temp matches the target temp\n",
    "        if temp_value == target_temp:\n",
    "            # Load the current CSV file\n",
    "            csv_path = os.path.join(directory, filename)\n",
    "            data_df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Merge the data based on the 'hash' column\n",
    "            merged_df = pd.merge(master_df, data_df[['hash', 'gpt-4o-2024-05-13']], on='hash', how='left')\n",
    "            \n",
    "            # Add columns for the temp and model name\n",
    "            merged_df[f'gpt-4o-2024-05-13_temp_{temp_value}'] = merged_df['gpt-4o-2024-05-13']\n",
    "            \n",
    "            # Drop the intermediate 'gpt-4o-2024-05-13' column after merging\n",
    "            merged_df.drop(columns=['gpt-4o-2024-05-13'], inplace=True)\n",
    "            \n",
    "            # Update the prompts.csv DataFrame\n",
    "            master_df = merged_df\n",
    "\n",
    "# Save the updated prompts.csv\n",
    "master_df.to_csv(data_master_path , index=False)\n",
    "\n",
    "print(f\"{data_master_path} updated successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
